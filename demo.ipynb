{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for test functions for all kind of data processing\n",
    "\n",
    "## Tasks:\n",
    "* Detect events:\n",
    "    * Pitcher:\n",
    "        * first movement\n",
    "        * ball release\n",
    "    * Batter:\n",
    "        * Foot highest, foot back to ground\n",
    "        * First step (when starting to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b4a2dd5530a6>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b4a2dd5530a6>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    from 2_Event_Detection.run_events import Runner\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import json\n",
    "from os import listdir\n",
    "import cv2\n",
    "import time\n",
    "import ast\n",
    "import json\n",
    "from run_events import Runner\n",
    "from test import test\n",
    "# import matplotlib.pylab as plt\n",
    "#from notebooks.code_to_json import from_json\n",
    "\n",
    "from data_preprocess import JsonProcessor\n",
    "from tools import Tools\n",
    "from test import test\n",
    "# path_outputs = \"/Volumes/Nina Backup/finished_outputs/\"\n",
    "# test_json_files = \"/Volumes/Nina Backup/high_quality_outputs/\"\n",
    "# test_data_path = \"/Users/ninawiedemann/Desktop/UNI/Praktikum/high_quality_testing/pitcher/\"\n",
    "# save =  \"/Users/ninawiedemann/Desktop/UNI/Praktikum/ALL/saved_models/pitch_type_svcf\"\n",
    "\n",
    "# import functions:\n",
    "# first_move_batter_gradient, first_move_batter_NN, release_frame_conv_net, release_frame_2Dfrom_video, foot_to_ground\n",
    "from detect_event import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_json(file):\n",
    "    coordinates = [\"x\", \"y\"]\n",
    "    joints_list = [\"right_shoulder\", \"right_elbow\", \"right_wrist\", \"left_shoulder\",\"left_elbow\", \"left_wrist\",\n",
    "            \"right_hip\", \"right_knee\", \"right_ankle\", \"left_hip\", \"left_knee\", \"left_ankle\",\n",
    "            \"right_eye\", \"right_ear\",\"left_eye\", \"left_ear\", \"nose \", \"neck\"]\n",
    "    with open(file, 'r') as inf:\n",
    "        out = json.load(inf)\n",
    "\n",
    "    liste = []\n",
    "    for fr in out[\"frames\"]:\n",
    "        l_joints = []\n",
    "        for j in joints_list[:12]:\n",
    "            l_coo = []\n",
    "            for xy in coordinates:\n",
    "                l_coo.append(fr[j][xy])\n",
    "            l_joints.append(l_coo)\n",
    "        liste.append(l_joints)\n",
    "\n",
    "    return np.array(liste)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "joints_list = [\"right_shoulder\", \"right_elbow\", \"right_wrist\", \"left_shoulder\",\"left_elbow\", \"left_wrist\",\n",
    "        \"right_hip\", \"right_knee\", \"right_ankle\", \"left_hip\", \"left_knee\", \"left_ankle\", \"neck \",\n",
    "        \"right_eye\", \"right_ear\",\"left_eye\", \"left_ear\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#csv = pd.read_csv(\"train_data/csv_gameplay.csv\", delimiter=\";\")\n",
    "#line = csv[csv[\"play_id\"]==\"f4ea3410-f559-464f-acb0-74133d7742e3\"]\n",
    "#print(line[\"Pitch Type\"])\n",
    "#print(line[\"Play Outcome\"])\n",
    "\n",
    "example = \"demo_data/example_1\" # f4ea3410-f559-464f-acb0-74133d7742e3\n",
    "pitcher = from_json(example+\"_pitcher.json\")\n",
    "batter = from_json(example+\"_batter.json\")\n",
    "with open(example+\"_video_batter.json\", \"r\") as infile:\n",
    "    videos_b = json.load(infile)\n",
    "with open(example+\"_video_pitcher.json\", \"r\") as infile:\n",
    "    videos_p = json.load(infile)\n",
    "with open(example+\"_labels.json\", \"r\") as infile:\n",
    "    labels = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize pitcher and batter joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for video, person in zip([\"videos_b\", \"videos_p\"], [\"batter\", \"pitcher\"]):\n",
    "    print(\"--------------------\", person, \"------------------------\")\n",
    "    plt.figure(figsize = (10,10))\n",
    "    for j in joints_list[:12]:\n",
    "        plt.plot(eval(person)[:,joints_list.index(j), 0], np.arange(0,len(eval(person)),1), label = j)\n",
    "    plt.title(\"X trajectories\")\n",
    "    plt.ylim(167,0)\n",
    "    plt.ylabel(\"Frame\")\n",
    "    plt.xlabel(\"X coordinate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot video frames to visualize maxima in X coordinates\n",
    "    show_frames = [30, 75, 85, 100, 130, 150]\n",
    "    fig = plt.figure(figsize=(20, 5))\n",
    "    for ind, i in enumerate(show_frames):\n",
    "        ax = fig.add_subplot(1,len(show_frames),ind+1)\n",
    "        plt.imshow(eval(video)[i])\n",
    "        plt.title(\"frame \"+str(i))\n",
    "        plt.gray()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize = (20,10))\n",
    "    for j in joints_list[:12]: #[one_joint]: \n",
    "        plt.plot(eval(person)[:,joints_list.index(j), 1], label = j)\n",
    "    plt.legend()\n",
    "    plt.ylim(350, 140)\n",
    "    plt.ylabel(\"Y coordinate\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.title(\"Y trajectories\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release frame: \n",
    "\n",
    "First neural network has sequence of 100 frames joint trajectory as input and \n",
    "detectes from joints which one is most likeley to be the release frame\n",
    "\n",
    "Second neural network outputs probability for a single IMAGE to be a release position, and outputs the one with highest probability as the release frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RELEASE FROM TRAJECTORIES APPROACH\n",
    "\n",
    "# Testing different models and different cut offs (network is not very consistent)\n",
    "for modl in [\"smooth\", \"general\", \"minmax\", \"combined\"]:\n",
    "    l = []\n",
    "    for i in range(20, 50, 10):\n",
    "        # needs to be cut to length 100\n",
    "        release_from_trajectory = release_frame_conv_net(np.array([pitcher[i:i+100]]), \n",
    "                            model = \"saved_models/release_frame_\"+modl)\n",
    "        l.append(release_from_trajectory[0,0]+i)\n",
    "    print(l, \"model\", modl, \"mean\", np.mean(l))\n",
    "\n",
    "release_from_trajectory = int(np.mean(l))\n",
    "print(\"---- Release frame from trajectories approach: \", release_from_trajectory, \"--------\")\n",
    "# Plot\n",
    "show_frames = range(release_from_trajectory-2, release_from_trajectory+2)\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for ind, i in enumerate(show_frames):\n",
    "    ax = fig.add_subplot(1,len(show_frames),ind+1)\n",
    "    plt.imshow(videos_p[i])\n",
    "    plt.gray()\n",
    "    plt.title(\"frame \"+str(i))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# IMAGE RELEASE POSITION APPROACH\n",
    "\n",
    "video_file = example+\".mp4\"\n",
    "\n",
    "# For the image classification, a region of interest is required / helpful\n",
    "for i in open(video_file+\".dat\").readlines():\n",
    "        datContent=ast.literal_eval(i)        \n",
    "bottom_p=datContent['Pitcher']['bottom']\n",
    "left_p=datContent['Pitcher']['left']\n",
    "right_p=datContent['Pitcher']['right']\n",
    "top_p=datContent['Pitcher']['top']\n",
    "\n",
    "box = [left_p, right_p, top_p, bottom_p] # bounding box \n",
    "\n",
    "# RUN Release frame from video function\n",
    "release_from_video, release_probs = release_frame_2Dfrom_video(video_file, bbox = box, model = \"saved_models/release_model\")\n",
    "\n",
    "print(\"---- Image release position approach: \", release_from_video, \"--------\")\n",
    "# Plot\n",
    "show_frames = range(release_from_video-2, release_from_video+2)\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax = fig.add_subplot(1,len(show_frames)+1,1)\n",
    "plt.plot(release_probs)\n",
    "plt.title(\"Release frame probabilities\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Probability\")\n",
    "for ind, i in enumerate(show_frames):\n",
    "    ax = fig.add_subplot(1,len(show_frames)+1,ind+2)\n",
    "    plt.imshow(videos_p[i])\n",
    "    plt.gray()\n",
    "    plt.title(\"frame \"+str(i))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# FOR SINGLE IMAGE CLASSIFICATION: no extra function, just use test\n",
    "release_image = np.array(videos_p[release_from_video])\n",
    "input_release_frame = cv2.resize(release_image,(55, 55), interpolation = cv2.INTER_LINEAR)/255\n",
    "data = np.reshape(input_release_frame, (1, 55, 55, 1))\n",
    "lab, out = test(data, \"saved_models/release_model\")\n",
    "release_probability_from_image = out[0,1]\n",
    "print(\"---- Release frame from trajectories approach: \", release_probability_from_image, \"--------\")\n",
    "plt.imshow(input_release_frame)\n",
    "plt.show()\n",
    "print(\"might be a lower value because format of saved videos_p array is different from the normal region of interest, it is recommended to take the first frame with prob >0.1 of a new video as the release frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batter's first movement: gradient and neural network method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gradient method\n",
    "first_batter_gradient = first_move_gradient(batter)\n",
    "# neural network\n",
    "first_move_nn = first_move_batter_NN(np.array([batter]), [90], model = \"saved_models/batter_first_rnn_10_40\")[0] # LATER HERE RELEASE FRAME\n",
    "print(\"--------------START RUN: network:\", first_move_nn, \", gradient: \", first_move_gradient, \"------------------\")\n",
    "plt.figure(figsize = (20,10))\n",
    "for j in joints_list[6:12]:\n",
    "    plt.plot(batter[:,joints_list.index(j), 0], label = j)\n",
    "plt.scatter([first_move_nn for _ in range(6)], batter[first_move_nn, 6:12, 0],  label = \"neural network\", color = \"red\")\n",
    "plt.scatter([first_batter_gradient for _ in range(6)], batter[first_batter_gradient, 6:12, 0], label = \"gradient\")\n",
    "plt.legend()\n",
    "plt.title(\"X gradient\")\n",
    "plt.show()\n",
    "\n",
    "show_frames = range(first_batter_gradient-3, first_batter_gradient+3)\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for ind, i in enumerate(show_frames):\n",
    "    ax = fig.add_subplot(1,len(show_frames),ind+1)\n",
    "    plt.imshow(videos_b[i])\n",
    "    plt.gray()\n",
    "    plt.title(\"frame \"+str(i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment batter puts foot down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relevant_joints =[7,8,10,11]\n",
    "\n",
    "foot_up, foot_down_gradient = foot_to_ground(batter, release= release_from_video, start_run = first_move_nn)\n",
    "    \n",
    "print(\"first step\", first_move_nn, \"foot highest\", foot_up, \"foot down\", foot_down_gradient)\n",
    "\n",
    "print(\"--------------moment batter puts foot down\", foot_down_gradient, \"------------------\")\n",
    "plt.figure(figsize = (20,10))\n",
    "for j in joints_list[6:12]:\n",
    "    plt.plot(batter[:,joints_list.index(j), 1], label = j)\n",
    "plt.scatter([first_move_nn for _ in range(6)], batter[first_move_nn, 6:12, 1],  label = \"starts run\", color = \"blue\")\n",
    "plt.scatter([foot_up for _ in range(6)], batter[foot_up, 6:12, 1],  label = \"foot highest\", color = \"green\")\n",
    "plt.scatter([foot_down_gradient for _ in range(6)], batter[foot_down_gradient, 6:12, 1],  label = \"foot down\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.title(\"Y gradient\")\n",
    "plt.show()\n",
    "\n",
    "show_frames = range(foot_down_gradient-3, foot_down_gradient+3)\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for ind, i in enumerate(show_frames):\n",
    "    ax = fig.add_subplot(1,len(show_frames),ind+1)\n",
    "    plt.imshow(videos_b[i])\n",
    "    plt.gray()\n",
    "    plt.title(\"frame \"+str(i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast moving object detection - for pitcher's first movement, ball detection and ball release frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fom_detection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Release frame and ball trajectory\n",
    "\n",
    "works better with side view video, because green background for ball detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BASE = example+\".m4v\"\n",
    "box = [400, 800, 600, 1400]\n",
    "ball_release, ball_trajectory, _ = detect_ball(BASE, joints_array = None, plotting=False, min_area=30, every_x_frame=4, roi=box)\n",
    "print(\"output:\", ball_release, ball_trajectory.tolist())\n",
    "print(\"The release frame predicted above is correct, althought 98 != 92, because center field camera and side view camera are not synchronized\")\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "cap = cv2.VideoCapture(example+\".m4v\")\n",
    "p=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if p==ball_release:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(frame[400:600, 600:800])\n",
    "        plt.title(\"Detected release frame from FMO detection:\")\n",
    "        break\n",
    "    p+=1\n",
    "    \n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(ball_trajectory[:,0], ball_trajectory[:,1])\n",
    "plt.ylim(350, 0)\n",
    "plt.xlim(0, 800)\n",
    "plt.title(\"Ball trajectory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitcher's first movement:\n",
    "\n",
    "### with FMO detection and with gradient\n",
    "FMO detection for pitcher's first movement: better with center field video (and in this notebook only pose estimation for center field video is used)\n",
    "\n",
    "Definition for pitcher's first movement: highest point of his leg when lifting his leg (then the video can be saved from 10 frames before\n",
    "\n",
    "changes to fmo detection for release frame:\n",
    "* joints array used (approach works by looking for FMO detections close to knee/ankle in some consecutive frames)\n",
    "* bigger min_area used\n",
    "* no roi required\n",
    "* every_x_frame = 4 means that only every fourth frame is compared, such that slower movements are detected than for the ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BASE = example+\".mp4\"\n",
    "#tic = time.time()\n",
    "_, _, first_move_frame = detect_ball(BASE, joints_array = pitcher, plotting=False, min_area=50, every_x_frame=4)\n",
    "#print(\"performance is real time: time for 70 frames with plotting:\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# changes to batter: \n",
    "# relevant_coordinate: Y coordinate (because lifting of leg) \n",
    "# relevant_joints_list: only knees and ankles\n",
    "relevant_joints =[7,8,10,11]\n",
    "first_pitcher_gradient = first_move_gradient(pitcher, relevant_joints_list=relevant_joints, relevant_coordinate=1, cutoff=2)\n",
    "\n",
    "\n",
    "print(\"--------------START RUN: FMO detection:\", first_move_frame, \", gradient: \", first_pitcher_gradient, \"------------------\")\n",
    "plt.figure(figsize = (20,10))\n",
    "for j in np.array(joints_list)[[relevant_joints]]:\n",
    "    plt.plot(pitcher[:,joints_list.index(j), 1], label = j)\n",
    "plt.scatter([first_move_frame for _ in range(len(relevant_joints))], pitcher[first_move_frame, relevant_joints, 1],  label = \"FMO detection\", color = \"red\")\n",
    "plt.scatter([first_pitcher_gradient for _ in range(len(relevant_joints))], pitcher[first_pitcher_gradient, relevant_joints, 1], label = \"gradient\")\n",
    "plt.legend()\n",
    "plt.title(\"Y gradient\")\n",
    "plt.ylim(350, 200)\n",
    "plt.show()\n",
    "\n",
    "show_frames = range(first_pitcher_gradient-5, first_pitcher_gradient+1)\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "for ind, i in enumerate(show_frames):\n",
    "    ax = fig.add_subplot(1,len(show_frames),ind+1)\n",
    "    plt.imshow(videos_p[i])\n",
    "    plt.gray()\n",
    "    plt.title(\"frame \"+str(i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeline - all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pitcher_events = {\"First move (FMO)\": first_move_frame, \"First move (gradient)\": first_pitcher_gradient,\n",
    "                 \"Ball release (FMO- wrong because other video!!)\": ball_release, \"Ball release (trajectories NN)\": release_from_trajectory,\n",
    "                 \"Ball release (NN - position in image)\": release_from_video}\n",
    "batter_events = {\"Foot highest\": foot_up, \"Foot down (gradient)\": foot_down_gradient, \n",
    "                \"First step (gradient)\": first_batter_gradient, \"First step (trajectories NN)\": first_move_nn}\n",
    "col=[\"green\", \"blue\",\"red\", \"purple\",\"black\", \"gray\", \"orange\", \"yellow\", \"brown\", \"pink\", \"black\"]\n",
    "co = [\"x\",\"y\"]\n",
    "# PITCHER\n",
    "limits = [450, 150]\n",
    "plt.figure(figsize = (20,10))\n",
    "for j in [0,1]:\n",
    "    plt.plot(pitcher[:,:, j], label = co[j], color = col[j])\n",
    "for i, event in enumerate(list(pitcher_events.keys())):\n",
    "    plt.plot([pitcher_events[event], pitcher_events[event]], limits, color=col[i+2], label=event)\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"Pitcher - Timeline on trajectories\", fontsize=20)\n",
    "plt.ylim(limits[0], limits[1])\n",
    "plt.ylabel(\"X/Y value\", fontsize=20)\n",
    "plt.xlabel(\"Frame index\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# BATTER foot_up, foot_down_gradient first_move_gradient first_move_nn\n",
    "limits = [600, 100]\n",
    "plt.figure(figsize = (20,10))\n",
    "for j in [0,1]:\n",
    "    plt.plot(batter[:,:, j], label = co[j], color = col[j])\n",
    "for i, event in enumerate(list(batter_events.keys())):\n",
    "    plt.plot([batter_events[event], batter_events[event]], limits, color=col[i+7], label=event)\n",
    "plt.legend(fontsize=20)\n",
    "# plt.title(\"Batter - Timeline on trajectories\")\n",
    "plt.ylim(limits[0], limits[1])\n",
    "plt.ylabel(\"X/Y value\", fontsize=20)\n",
    "plt.xlabel(\"Frame index\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "pitcher_array = np.roll(pitcher, 2, axis = 1)\n",
    "batter_array = np.roll(batter, 2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"/Volumes/Nina Backup/high_quality_testing/pitcher/#42 LHP Michael Chavez.mp4\") #26 RHP Tim Willites (2).mp4\") #example+\".mp4\")\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 470)\n",
    "_, canvas = cap.read()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(canvas)\n",
    "plt.savefig(\"canvas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "limbSeq = [[0,1], [1,2], [0,3], [3,4], [4,5], [6,9],[6,7], [7,8],[9,10],[10,11], [0,6], [3,9]]\n",
    "stickwidth = 8\n",
    "colors = [[255, 0, 0], [120, 0, 0], [255, 255, 0], [255, 120, 0], [200, 100, 0], [120, 120, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "cap = cv2.VideoCapture(\"/Volumes/Nina Backup/high_quality_testing/pitcher/#42 LHP Michael Chavez.mp4\") #26 RHP Tim Willites (2).mp4\") #example+\".mp4\")\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 470)\n",
    "_, canvas = cap.read()\n",
    "canvas = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "pitcher = from_json(\"/Volumes/Nina Backup/low_quality_testing/scale0tests/#42 LHP Michael Chavez.json\")\n",
    "plt.figure(figsize =(20,10))\n",
    "ball_trajectory = [[479, (525, 241), (568, 282)], [480, (416, 245), (451, 280)], [481, (304, 241), (344, 272)], \n",
    "                   [482, (176, 235), (224, 272)], [483, (56, 229), (104, 262)]]\n",
    "frame_list = [0, 400, 450, 490]\n",
    "for j in range(len(pitcher)):\n",
    "    if j >=ball_trajectory[0][0] and j<=ball_trajectory[-1][0]:\n",
    "        cand = ball_trajectory[j-ball_trajectory[0][0]]\n",
    "        cv2.rectangle(canvas, cand[1], cand[2],[255,0,0], 4)\n",
    "    if j in frame_list:\n",
    "        for player in [\"pitcher\"]:\n",
    "            for i, inds in enumerate(limbSeq):\n",
    "                if inds[0]>11 or inds[1]>11:\n",
    "                    continue\n",
    "                Y = eval(player)[j,inds, 0]\n",
    "                X = eval(player)[j,inds, 1]\n",
    "                mX = np.mean(X)\n",
    "                mY = np.mean(Y)\n",
    "                cur_canvas = canvas.copy()\n",
    "                length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "                angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "                polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "                cv2.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "                canvas = cv2.addWeighted(canvas, 0.1, cur_canvas, 0.9, 0)\n",
    "plt.imshow(canvas)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
